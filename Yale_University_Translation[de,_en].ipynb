{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall torch -y\n",
        "# !pip uninstall torchtext -y\n",
        "# !pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio===0.10.1+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
        "# !pip install torchtext==0.9.0"
      ],
      "metadata": {
        "id": "-0--_9yGFGLk"
      },
      "execution_count": 733,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "id": "YbZfGEd3GYiX"
      },
      "execution_count": 734,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exit()"
      ],
      "metadata": {
        "id": "Ag_V0bASF_sV"
      },
      "execution_count": 735,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparing the Data**"
      ],
      "metadata": {
        "id": "5iUZYrPgG3pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator, Dataset, Example, TabularDataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6sku0_bXRmLx"
      },
      "execution_count": 736,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo0UkSfEXkd3",
        "outputId": "9590ca69-0532-4830-fb69-a7b6bee7d013"
      },
      "execution_count": 737,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "-q2DBw9cLBLX"
      },
      "execution_count": 738,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset:\n",
        "  def __init__(self, filepath):\n",
        "    self.spacy_en = spacy.load('en_core_web_sm')\n",
        "    self.spacy_de = spacy.load('de_core_news_sm')\n",
        "    self.SRC = Field(tokenize=self.tokenize_de, \n",
        "                init_token='<sos>', \n",
        "                eos_token='<eos>', \n",
        "                lower=True, \n",
        "                batch_first=True)\n",
        "    self.TRG = Field(tokenize=self.tokenize_en, \n",
        "                init_token='<sos>', \n",
        "                eos_token='<eos>', \n",
        "                lower=True, \n",
        "                batch_first=True)\n",
        "    self.dataset = TabularDataset(\n",
        "        path=filepath, format='tsv', skip_header=True,\n",
        "        fields=[('trg', self.TRG), ('src', self.SRC)]\n",
        "    )\n",
        "    \n",
        "  def __len__(self):\n",
        "    length = len(self.dataset)\n",
        "    return length\n",
        "\n",
        "  def tokenize_de(self, text):\n",
        "    tokens = [tok.text for tok in self.spacy_de.tokenizer(text)]\n",
        "    if not tokens:\n",
        "        return []\n",
        "    return tokens\n",
        "\n",
        "  def tokenize_en(self, text):\n",
        "    tokens = [tok.text for tok in self.spacy_en.tokenizer(text)]\n",
        "    if not tokens:\n",
        "        return []\n",
        "    return tokens\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    en = self.dataset[idx].trg\n",
        "    de = self.dataset[idx].src\n",
        "    return de, en\n",
        "\n",
        "  def splitDataset(self, batch_size=32):\n",
        "    train_data, valid_data, test_data = self.dataset.split(split_ratio=[0.8, 0.1, 0.1])\n",
        "    return train_data, valid_data, test_data\n",
        "  \n",
        "  def buildVocab(self, data):\n",
        "    self.SRC.build_vocab(train_data, min_freq = 2)\n",
        "    self.TRG.build_vocab(train_data, min_freq = 2)\n",
        "  \n",
        "  def setIterator(self, train_data, valid_data, test_data, batch_size=32):\n",
        "    train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \n",
        "                                                      batch_size=batch_size,\n",
        "                                                      device=device,\n",
        "                                                      sort_key=lambda x: len(x.src),\n",
        "                                                      sort_within_batch=True,\n",
        "                                                    )\n",
        "    return train_iterator, valid_iterator, test_iterator\n",
        "\n",
        "  \n",
        "  def getSrcTrg(self):\n",
        "    return self.SRC, self.TRG\n"
      ],
      "metadata": {
        "id": "0qCTZRP7kItH"
      },
      "execution_count": 739,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "kfHVZMO99mwJ"
      },
      "execution_count": 740,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TranslationDataset('/content/drive/MyDrive/filtered_dataset2.tsv')"
      ],
      "metadata": {
        "id": "oD1RhkiCXe3E"
      },
      "execution_count": 741,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JYr3szOJ8tK",
        "outputId": "dbc83538-f43c-4877-dc4d-b6f4bd5be339"
      },
      "execution_count": 742,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "261"
            ]
          },
          "metadata": {},
          "execution_count": 742
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[8]"
      ],
      "metadata": {
        "id": "P2bwSc_6OGSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f7d4b7-d36d-4f1c-c121-f79c582442b8"
      },
      "execution_count": 743,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['umweltschule'], ['school', 'of', 'the', 'environment'])"
            ]
          },
          "metadata": {},
          "execution_count": 743
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = dataset.splitDataset(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "SEawFpYkXsQR"
      },
      "execution_count": 744,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.buildVocab(train_data)"
      ],
      "metadata": {
        "id": "lHTfyHcloilB"
      },
      "execution_count": 745,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, valid_iterator, test_iterator = dataset.setIterator(train_data, valid_data, test_data, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "-h4Yq1rDorv7"
      },
      "execution_count": 746,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC, TRG = dataset.getSrcTrg()"
      ],
      "metadata": {
        "id": "2kBouTr6z94a"
      },
      "execution_count": 747,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_iterator:\n",
        "    print(batch)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq_UT0zxY4C4",
        "outputId": "ca407b21-a57c-431c-bb01-532be1826f32"
      },
      "execution_count": 748,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 128]\n",
            "\t[.trg]:[torch.LongTensor of size 128x11]\n",
            "\t[.src]:[torch.LongTensor of size 128x9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the Model**"
      ],
      "metadata": {
        "id": "2wHHDdfpGrdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder**"
      ],
      "metadata": {
        "id": "SM-QVlpoIY4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))  \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "metadata": {
        "id": "_rPy7y-OHFrD"
      },
      "execution_count": 749,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "metadata": {
        "id": "RpuVkkTQHXfP"
      },
      "execution_count": 750,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        batch_size = query.shape[0]\n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "metadata": {
        "id": "5aXcleHAHaPy"
      },
      "execution_count": 751,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "r1QEQ3OVHn03"
      },
      "execution_count": 752,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder**"
      ],
      "metadata": {
        "id": "CJvj3Al-Idvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "e4owmFQbIf93"
      },
      "execution_count": 753,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "metadata": {
        "id": "qlvG4IwwIomY"
      },
      "execution_count": 754,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        #src = [batch size, src len]\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention\n"
      ],
      "metadata": {
        "id": "tDyIAvb1Jtuu"
      },
      "execution_count": 755,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Model**"
      ],
      "metadata": {
        "id": "whDxYzEf_mLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "metadata": {
        "id": "b2h8rSA8HZTX"
      },
      "execution_count": 756,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "metadata": {
        "id": "C0_dYj0yLURs"
      },
      "execution_count": 757,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ71bmmgLZlN",
        "outputId": "6a96dac6-0155-4709-eb44-80b16f13a147"
      },
      "execution_count": 758,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 4,154,315 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "metadata": {
        "id": "4Yydq6HsLnQ6"
      },
      "execution_count": 759,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.apply(initialize_weights);"
      ],
      "metadata": {
        "id": "x5pWwunJLoQ4"
      },
      "execution_count": 760,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "metadata": {
        "id": "8ERwN6EvZVUa"
      },
      "execution_count": 761,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "V3GTHtJnL0x5"
      },
      "execution_count": 762,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "vDvsIrWKL5Q4"
      },
      "execution_count": 763,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "1AFAN-P6L9d2"
      },
      "execution_count": 764,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "kwOhsfkdMBNh"
      },
      "execution_count": 765,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import time"
      ],
      "metadata": {
        "id": "HJ73d4XJMNK1"
      },
      "execution_count": 766,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the size of the SRC and TRG vocabularies\n",
        "print(len(SRC.vocab), len(TRG.vocab))\n",
        "\n",
        "# Get a batch from the iterator\n",
        "batch = next(iter(train_iterator))\n",
        "\n",
        "# Print the maximum index value in the input tensor\n",
        "print(torch.max(batch.src).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKBW-zGGpUYa",
        "outputId": "f7d7695f-0ce3-4e53-ad88-e5c451a1ed7d"
      },
      "execution_count": 767,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "177 203\n",
            "176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.max(batch.src).item())\n",
        "print(enc.tok_embedding.weight.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUApkeSLu_Ek",
        "outputId": "39c06007-a963-4f62-cf64-5c6195e5a8a4"
      },
      "execution_count": 768,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176\n",
            "torch.Size([177, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding best learning rate**"
      ],
      "metadata": {
        "id": "048GS0tpT-Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def find_best_learning_rate(model, train_loader, start_lr=0.0001, end_lr=0.1, num_iters=50, device='cpu'):\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=start_lr)\n",
        "#     # optimizer = optim.SGD(model.parameters(), lr=start_lr)\n",
        "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=10)\n",
        "    \n",
        "#     lr_list = []\n",
        "#     loss_list = []\n",
        "    \n",
        "#     for i in range(num_iters):\n",
        "#         lr = start_lr + (end_lr - start_lr) * i / (num_iters - 1)\n",
        "#         optimizer.param_groups[0]['lr'] = lr\n",
        "#         scheduler.step()\n",
        "        \n",
        "#         for batch in train_loader:\n",
        "#             src = batch.src.to(device)\n",
        "#             trg = batch.trg.to(device)\n",
        "            \n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(src, trg[:,:-1])  # exclude <eos> token from decoder input\n",
        "#             outputs = outputs[0].contiguous().view(-1, outputs[0].shape[-1])  # reshape for loss computation\n",
        "#             labels = trg[:,1:].contiguous().view(-1)  # exclude <sos> token from target\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "        \n",
        "#         loss_list.append(loss.item())\n",
        "#         lr_list.append(lr)\n",
        "        \n",
        "#     # Find the optimal learning rate\n",
        "#     grad = torch.tensor([loss_list[i+1] - loss_list[i] for i in range(len(loss_list)-1)])\n",
        "#     idx = torch.argmax(grad).item()\n",
        "#     best_lr = lr_list[idx]\n",
        "    \n",
        "#     return best_lr, lr_list, loss_list"
      ],
      "metadata": {
        "id": "T9wLsiICXRz1"
      },
      "execution_count": 769,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LEARNING_RATE = 0.0005\n",
        "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "# CLIP = 1\n",
        "# best_lr = 0\n",
        "# best_valid_loss = float('inf')  # initialize to a large value\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     # Train the model for one epoch\n",
        "#     train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    \n",
        "#     # Evaluate the model on the validation dataset\n",
        "#     valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "#     # Update the learning rate based on the validation loss\n",
        "#     if valid_loss < best_valid_loss:\n",
        "#         best_valid_loss = valid_loss\n",
        "#         best_lr = LEARNING_RATE\n",
        "#         LEARNING_RATE *= 1.1\n",
        "#     else:\n",
        "#         LEARNING_RATE /= 2\n",
        "#         optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# print(f\"Best Learning Rate: {best_lr}\")\n",
        "# LEARNING_RATE = best_lr\n",
        "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "NqXXraX1T9hR"
      },
      "execution_count": 770,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/model.pt'"
      ],
      "metadata": {
        "id": "E53yoakQ9rzX"
      },
      "execution_count": 771,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_lr = find_best_learning_rate(model, train_iterator, device=device)"
      ],
      "metadata": {
        "id": "z5O8fVck7grw"
      },
      "execution_count": 772,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_lr"
      ],
      "metadata": {
        "id": "IvIGUMttXvxz"
      },
      "execution_count": 773,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# N_EPOCHS = 100\n",
        "# CLIP = 1\n",
        "\n",
        "# best_valid_loss = float('inf')\n",
        "# trainLoss = []\n",
        "# validLoss = []\n",
        "\n",
        "# for epoch in range(N_EPOCHS):\n",
        "    \n",
        "#     start_time = time.time()\n",
        "    \n",
        "#     train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "#     valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "#     trainLoss.append(train_loss)\n",
        "#     validLoss.append(valid_loss)\n",
        "    \n",
        "#     end_time = time.time()\n",
        "    \n",
        "#     epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "#     if valid_loss < best_valid_loss:\n",
        "#         best_valid_loss = valid_loss\n",
        "#         torch.save(model.state_dict(), path)\n",
        "    \n",
        "#     print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "#     print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "QZ1EO9CoMH2j"
      },
      "execution_count": 774,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 100\n",
        "CLIP = 1\n",
        "PATIENCE = 10  # number of epochs to wait before stopping if validation loss doesn't improve\n",
        "best_valid_loss = float('inf')\n",
        "trainLoss = []\n",
        "validLoss = []\n",
        "no_improvement_count = 0  # number of epochs since validation loss improved\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    trainLoss.append(train_loss)\n",
        "    validLoss.append(valid_loss)\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), path)\n",
        "        no_improvement_count = 0\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "        if no_improvement_count >= PATIENCE:\n",
        "            print(f'Validation loss hasn\\'t improved for {PATIENCE} epochs. Stopping early.')\n",
        "            break\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3AtZIZT5crn",
        "outputId": "0be0bfcf-fb24-469e-9661-8b30a66183c5"
      },
      "execution_count": 775,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 2s\n",
            "\tTrain Loss: 5.355 | Train PPL: 211.709\n",
            "\t Val. Loss: 3.737 |  Val. PPL:  41.990\n",
            "Epoch: 02 | Time: 0m 4s\n",
            "\tTrain Loss: 4.227 | Train PPL:  68.517\n",
            "\t Val. Loss: 3.198 |  Val. PPL:  24.489\n",
            "Epoch: 03 | Time: 0m 2s\n",
            "\tTrain Loss: 4.185 | Train PPL:  65.692\n",
            "\t Val. Loss: 3.059 |  Val. PPL:  21.309\n",
            "Epoch: 04 | Time: 0m 2s\n",
            "\tTrain Loss: 4.021 | Train PPL:  55.753\n",
            "\t Val. Loss: 2.967 |  Val. PPL:  19.436\n",
            "Epoch: 05 | Time: 0m 2s\n",
            "\tTrain Loss: 3.932 | Train PPL:  51.019\n",
            "\t Val. Loss: 3.045 |  Val. PPL:  21.013\n",
            "Epoch: 06 | Time: 0m 2s\n",
            "\tTrain Loss: 3.885 | Train PPL:  48.645\n",
            "\t Val. Loss: 2.913 |  Val. PPL:  18.410\n",
            "Epoch: 07 | Time: 0m 2s\n",
            "\tTrain Loss: 3.847 | Train PPL:  46.840\n",
            "\t Val. Loss: 2.915 |  Val. PPL:  18.445\n",
            "Epoch: 08 | Time: 0m 3s\n",
            "\tTrain Loss: 3.852 | Train PPL:  47.081\n",
            "\t Val. Loss: 2.924 |  Val. PPL:  18.607\n",
            "Epoch: 09 | Time: 0m 3s\n",
            "\tTrain Loss: 3.791 | Train PPL:  44.312\n",
            "\t Val. Loss: 2.894 |  Val. PPL:  18.073\n",
            "Epoch: 10 | Time: 0m 2s\n",
            "\tTrain Loss: 3.753 | Train PPL:  42.661\n",
            "\t Val. Loss: 2.987 |  Val. PPL:  19.833\n",
            "Epoch: 11 | Time: 0m 2s\n",
            "\tTrain Loss: 3.714 | Train PPL:  41.029\n",
            "\t Val. Loss: 2.942 |  Val. PPL:  18.955\n",
            "Epoch: 12 | Time: 0m 2s\n",
            "\tTrain Loss: 3.657 | Train PPL:  38.737\n",
            "\t Val. Loss: 2.883 |  Val. PPL:  17.861\n",
            "Epoch: 13 | Time: 0m 2s\n",
            "\tTrain Loss: 3.625 | Train PPL:  37.520\n",
            "\t Val. Loss: 2.835 |  Val. PPL:  17.024\n",
            "Epoch: 14 | Time: 0m 2s\n",
            "\tTrain Loss: 3.528 | Train PPL:  34.066\n",
            "\t Val. Loss: 2.826 |  Val. PPL:  16.883\n",
            "Epoch: 15 | Time: 0m 3s\n",
            "\tTrain Loss: 3.468 | Train PPL:  32.071\n",
            "\t Val. Loss: 2.932 |  Val. PPL:  18.764\n",
            "Epoch: 16 | Time: 0m 3s\n",
            "\tTrain Loss: 3.379 | Train PPL:  29.341\n",
            "\t Val. Loss: 2.797 |  Val. PPL:  16.387\n",
            "Epoch: 17 | Time: 0m 2s\n",
            "\tTrain Loss: 3.412 | Train PPL:  30.318\n",
            "\t Val. Loss: 2.751 |  Val. PPL:  15.655\n",
            "Epoch: 18 | Time: 0m 2s\n",
            "\tTrain Loss: 3.249 | Train PPL:  25.777\n",
            "\t Val. Loss: 3.154 |  Val. PPL:  23.421\n",
            "Epoch: 19 | Time: 0m 2s\n",
            "\tTrain Loss: 3.422 | Train PPL:  30.616\n",
            "\t Val. Loss: 2.992 |  Val. PPL:  19.925\n",
            "Epoch: 20 | Time: 0m 2s\n",
            "\tTrain Loss: 3.216 | Train PPL:  24.933\n",
            "\t Val. Loss: 2.671 |  Val. PPL:  14.450\n",
            "Epoch: 21 | Time: 0m 2s\n",
            "\tTrain Loss: 3.175 | Train PPL:  23.930\n",
            "\t Val. Loss: 2.613 |  Val. PPL:  13.638\n",
            "Epoch: 22 | Time: 0m 3s\n",
            "\tTrain Loss: 3.056 | Train PPL:  21.244\n",
            "\t Val. Loss: 2.667 |  Val. PPL:  14.402\n",
            "Epoch: 23 | Time: 0m 2s\n",
            "\tTrain Loss: 2.973 | Train PPL:  19.551\n",
            "\t Val. Loss: 2.690 |  Val. PPL:  14.729\n",
            "Epoch: 24 | Time: 0m 2s\n",
            "\tTrain Loss: 3.116 | Train PPL:  22.559\n",
            "\t Val. Loss: 2.719 |  Val. PPL:  15.172\n",
            "Epoch: 25 | Time: 0m 2s\n",
            "\tTrain Loss: 2.992 | Train PPL:  19.928\n",
            "\t Val. Loss: 2.671 |  Val. PPL:  14.451\n",
            "Epoch: 26 | Time: 0m 2s\n",
            "\tTrain Loss: 2.822 | Train PPL:  16.818\n",
            "\t Val. Loss: 2.558 |  Val. PPL:  12.905\n",
            "Epoch: 27 | Time: 0m 3s\n",
            "\tTrain Loss: 2.764 | Train PPL:  15.858\n",
            "\t Val. Loss: 2.542 |  Val. PPL:  12.704\n",
            "Epoch: 28 | Time: 0m 3s\n",
            "\tTrain Loss: 2.722 | Train PPL:  15.208\n",
            "\t Val. Loss: 2.550 |  Val. PPL:  12.810\n",
            "Epoch: 29 | Time: 0m 3s\n",
            "\tTrain Loss: 2.610 | Train PPL:  13.604\n",
            "\t Val. Loss: 2.522 |  Val. PPL:  12.454\n",
            "Epoch: 30 | Time: 0m 2s\n",
            "\tTrain Loss: 2.545 | Train PPL:  12.737\n",
            "\t Val. Loss: 2.528 |  Val. PPL:  12.527\n",
            "Epoch: 31 | Time: 0m 2s\n",
            "\tTrain Loss: 2.479 | Train PPL:  11.926\n",
            "\t Val. Loss: 2.525 |  Val. PPL:  12.486\n",
            "Epoch: 32 | Time: 0m 2s\n",
            "\tTrain Loss: 2.431 | Train PPL:  11.369\n",
            "\t Val. Loss: 2.534 |  Val. PPL:  12.598\n",
            "Epoch: 33 | Time: 0m 2s\n",
            "\tTrain Loss: 2.377 | Train PPL:  10.769\n",
            "\t Val. Loss: 2.492 |  Val. PPL:  12.085\n",
            "Epoch: 34 | Time: 0m 2s\n",
            "\tTrain Loss: 2.305 | Train PPL:  10.027\n",
            "\t Val. Loss: 2.552 |  Val. PPL:  12.828\n",
            "Epoch: 35 | Time: 0m 3s\n",
            "\tTrain Loss: 2.232 | Train PPL:   9.323\n",
            "\t Val. Loss: 2.589 |  Val. PPL:  13.310\n",
            "Epoch: 36 | Time: 0m 3s\n",
            "\tTrain Loss: 2.266 | Train PPL:   9.642\n",
            "\t Val. Loss: 2.524 |  Val. PPL:  12.475\n",
            "Epoch: 37 | Time: 0m 2s\n",
            "\tTrain Loss: 2.221 | Train PPL:   9.217\n",
            "\t Val. Loss: 2.603 |  Val. PPL:  13.502\n",
            "Epoch: 38 | Time: 0m 2s\n",
            "\tTrain Loss: 2.212 | Train PPL:   9.130\n",
            "\t Val. Loss: 2.546 |  Val. PPL:  12.755\n",
            "Epoch: 39 | Time: 0m 2s\n",
            "\tTrain Loss: 2.131 | Train PPL:   8.420\n",
            "\t Val. Loss: 2.555 |  Val. PPL:  12.874\n",
            "Epoch: 40 | Time: 0m 2s\n",
            "\tTrain Loss: 2.108 | Train PPL:   8.235\n",
            "\t Val. Loss: 2.543 |  Val. PPL:  12.712\n",
            "Epoch: 41 | Time: 0m 3s\n",
            "\tTrain Loss: 2.088 | Train PPL:   8.070\n",
            "\t Val. Loss: 2.673 |  Val. PPL:  14.478\n",
            "Epoch: 42 | Time: 0m 3s\n",
            "\tTrain Loss: 2.075 | Train PPL:   7.965\n",
            "\t Val. Loss: 2.529 |  Val. PPL:  12.539\n",
            "Validation loss hasn't improved for 10 epochs. Stopping early.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY_rReTa-9NX",
        "outputId": "3c6be45f-f1fa-43b6-d4a2-ce34c4856aef"
      },
      "execution_count": 776,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 2.450 | Test PPL:  11.592 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Translating using our model**"
      ],
      "metadata": {
        "id": "70tbtVycVUi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de_core_news_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "metadata": {
        "id": "1WPn_UfRUNXd"
      },
      "execution_count": 777,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = 4\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIssE6h9UPsp",
        "outputId": "0fe12623-1d41-498e-d707-f15eeef9b87c"
      },
      "execution_count": 778,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['school', 'of', 'public', 'health']\n",
            "trg = ['school', 'of', 'public', 'health']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjv8DhccUSb8",
        "outputId": "3696a68d-c9df-4fcf-c65d-eebed6328a52"
      },
      "execution_count": 779,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg = ['school', 'of', 'school', 'of', '<unk>', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = 33\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOBCtILNUX3C",
        "outputId": "c08b4a41-b805-40e3-ced2-2afa73353a75"
      },
      "execution_count": 780,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['in', 'den', 'medien']\n",
            "trg = ['in', 'the', 'media']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyuyIWyGUeUH",
        "outputId": "ed8d081f-db26-42da-df7a-459cb9e31085"
      },
      "execution_count": 781,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg = ['the', 'in', 'the', 'media', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = 40\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7gDHiaqU--x",
        "outputId": "d64e2f51-8a05-43ab-d728-4025615f54fe"
      },
      "execution_count": 782,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['die', 'yale', 'school', 'of', 'medicine', 'begrt', 'whrend', 'der', 'jhrlichen', 'white', 'coat-zeremonie', 'das', 'erste', 'studienjahr', 'zu', 'einem', 'leben', 'in', 'der', 'medizin', '.']\n",
            "trg = ['the', 'yale', 'school', 'of', 'medicine', 'welcomes', 'first', '-', 'year', 'students', 'to', 'a', 'life', 'in', 'medicine', 'during', 'the', 'annual', 'white', 'coat', 'ceremony', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdqM5FNBVDZZ",
        "outputId": "4ae7708b-1353-4409-9e0f-86397e2b0598"
      },
      "execution_count": 783,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg = ['the', 'the', 'yale', 'the', '<unk>', 'yale', 'the', '<unk>', 'of', 'the', '<unk>', 'the', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-', '<unk>', '-']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainLoss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OIVND8aw756",
        "outputId": "3a62c23f-8009-49a6-a691-908639db8d18"
      },
      "execution_count": 784,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 784
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the train loss and valid loss over epochs\n",
        "plt.plot(range(1, len(trainLoss)+1), trainLoss, label='Train Loss')\n",
        "plt.plot(range(1, len(trainLoss)+1), validLoss, label='Valid Loss')\n",
        "\n",
        "# Set the axis labels and title\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Valid Loss over Epochs')\n",
        "\n",
        "# Add the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Y16ICvGVtfhK",
        "outputId": "85dea11c-5d98-4c43-f9d9-725c180bd043"
      },
      "execution_count": 785,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}